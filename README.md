## ğŸ§  RAG Basics with LangChain + OpenAI API

This project introduces the fundamentals of **Retrieval-Augmented Generation (RAG)** by working with your own local markdown documents ğŸ“„. It uses the cost-effective `gpt-4o-mini` model ğŸ§‘â€ğŸ’» and demonstrates how to prepare a knowledge base so that large language models (LLMs) can generate more accurate, context-rich answers ğŸ’¡.

You'll learn how to load, split, and organize documents, annotate them with metadata, and search through them using LangChain ğŸ”. The environment is configured using a `.env` file, and the process helps build smart assistants or internal search tools that "understand" your documents ğŸ“š.

---

## ğŸ”— What is LangChain?

[LangChain](https://www.langchain.com/) is an open-source framework that helps developers connect **language models** with **external data sources** such as files, APIs, or databases.

Instead of relying solely on the modelâ€™s built-in knowledge, LangChain enables:

- ğŸ“„ Loading and reading custom documents
- âœ‚ï¸ Splitting large content into meaningful chunks
- ğŸ§  Storing them in vector databases for search and retrieval
- ğŸ” Combining search results with user queries to improve responses

Itâ€™s ideal for RAG-based systems that need to answer questions using **your own data**.

---

## âš™ï¸ How LangChain Helps in This Project

In this beginner-friendly RAG setup, LangChain:

- âœ… Loads `.md` files from your `knowledge-base/` folder
- âœ… Splits them into smaller, overlapping chunks
- âœ… Adds metadata to each chunk for easy filtering
- âœ… Allows keyword-based searches (like finding chunks with â€œCEOâ€)
- âœ… Prepares the content for retrieval with an OpenAI model

This sets the stage for building AI systems that are both intelligent and aware of your private knowledge ğŸ§ âœ¨.

---

## ğŸ” Program Flow

```text
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  ğŸ“ Read Markdown Documents  â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  âœ‚ï¸ Split Documents into Chunks     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ğŸ§  Annotate Each Chunk w/ Metadataâ”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ğŸ” Search or Filter Chunks (e.g. CEO)â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ğŸ’¡ Ready for Retrieval + LLM Use â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
